{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "redeNeuralv1ButBetter.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcmYZ//wgC7PsGtXqRp7O1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruiborreicho/RedeNeural/blob/main/redeNeuralv1ButBetter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rede Neural**"
      ],
      "metadata": {
        "id": "a0fK2RMndp6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Colheita de um dataset de imagens a ser utilizado na rede neural que pretendemos desenvolver**"
      ],
      "metadata": {
        "id": "NyIfCuo4dr8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação da diretoria em que serão armazenados os dados do dataset de nuImages, seguido da transferência do mesmo e a descompressão dos dados na diretoria anteriormente criada."
      ],
      "metadata": {
        "id": "PoAirJqjdvsi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ivwSNJDdhlL"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /nuimages  # Make the directory to store the nuImages dataset in.\n",
        "\n",
        "!wget https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz  # Download the nuImages mini split.\n",
        "\n",
        "!tar -xf nuimages-v1.0-mini.tgz -C /nuimages  # Uncompress the nuImages mini split.\n",
        "\n",
        "#!pip install nuscenes-devkit &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação da diretoria onde serão armazenadas todas as imagens."
      ],
      "metadata": {
        "id": "1SBXOAl01IbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /imagens"
      ],
      "metadata": {
        "id": "6R81sESN1J43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importações das bibliotecas que irão ser utilizadas"
      ],
      "metadata": {
        "id": "2APOrpg81MLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import shutil\n",
        "import os"
      ],
      "metadata": {
        "id": "ardHHbeR1OkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição da diretoria de origem dos ficheiros"
      ],
      "metadata": {
        "id": "BcCW4b0S1R8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = \"/nuimages\""
      ],
      "metadata": {
        "id": "RsU9ecFY1UcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição da diretoria de destino dos ficheiros"
      ],
      "metadata": {
        "id": "bXQsfVaj1WYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = \"/imagens\""
      ],
      "metadata": {
        "id": "gRKMsUWv1Yjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruções desenvolvidas que permitem a cópia de todos os ficheiros de formato .JPG da diretoria de origem para a diretoria de destino, que foram declaradas e definidas anteriormente."
      ],
      "metadata": {
        "id": "1IA3d4k91cLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /imagens/* #Delete all files located in imagens directory"
      ],
      "metadata": {
        "id": "0DdcmWNC1dOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for root, _, files in os.walk(src_dir, topdown=True):\n",
        "   for name in files:\n",
        "      if name.endswith('.jpg') :\n",
        "        file_path = os.path.join(root, name)\n",
        "        shutil.copy(file_path, dst_dir)"
      ],
      "metadata": {
        "id": "ndY9OIIP1f7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação de dependências"
      ],
      "metadata": {
        "id": "BYTNanos2Ep9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-api-python-client\n",
        "!pip install google-cloud\n",
        "!pip install google-cloud-vision"
      ],
      "metadata": {
        "id": "OP4PE23c2EUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação da biblioteca do Google Drive"
      ],
      "metadata": {
        "id": "VCSzbRJu2XPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "ue28dNtS2Xkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cópia das imagens para um diretório no Google Drive"
      ],
      "metadata": {
        "id": "chcmCnNV2Yav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -av \"/imagens\" \"/gdrive/MyDrive/IMAGENS\""
      ],
      "metadata": {
        "id": "OtzDEAtu2YvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Criação rede neural**"
      ],
      "metadata": {
        "id": "cMwAz6Je2poL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instalação de bibliotecas necessárias**"
      ],
      "metadata": {
        "id": "B7tkRcnY2ryd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do CUDA, CUDNN e Tensorflow"
      ],
      "metadata": {
        "id": "L7_0Ui_D6yBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check libcudnn8 version\n",
        "!apt-cache policy libcudnn8\n",
        "\n",
        "# Install latest version\n",
        "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6\n",
        "\n",
        "# Export env variables\n",
        "!export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}}\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64:$LD_LIBRARY_PATH\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda-11.4/include:$LD_LIBRARY_PATH\n",
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64\n",
        "\n",
        "# Install tensorflow\n",
        "!pip install tflite-model-maker==0.4.0\n",
        "!pip uninstall -y tensorflow && pip install -q tensorflow==2.9.1\n",
        "!pip install pycocotools==2.0.4\n",
        "!pip install opencv-python-headless==4.6.0.66"
      ],
      "metadata": {
        "id": "jM2GGjnh6ykG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificação da instalação da biblioteca tensorflow"
      ],
      "metadata": {
        "id": "5QiUiPXQ2wKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip show tensorflow"
      ],
      "metadata": {
        "id": "Up2HHh1x2qEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação da biblioteca tf_slim"
      ],
      "metadata": {
        "id": "q5yml0MP20k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf_slim"
      ],
      "metadata": {
        "id": "IOQxGxFh21CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação da biblioteca tensorflow_io"
      ],
      "metadata": {
        "id": "yyxBJoMB6CQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_io"
      ],
      "metadata": {
        "id": "4n6QNcq56CyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação da biblioteca tf-models-official"
      ],
      "metadata": {
        "id": "q43i3gIm6QKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tf-models-official"
      ],
      "metadata": {
        "id": "-9L7nAeS6Qrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação da biblioteca tensorflow-io"
      ],
      "metadata": {
        "id": "X0x9zbiR7LQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io"
      ],
      "metadata": {
        "id": "3kAZKg_P7MU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação da biblioteca tensorflow-object-detection-api"
      ],
      "metadata": {
        "id": "2b6JMhku7YM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-object-detection-api"
      ],
      "metadata": {
        "id": "FuH6jTWf7YgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação da biblioteca LVIS"
      ],
      "metadata": {
        "id": "Pdu9INIw6maT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lvis"
      ],
      "metadata": {
        "id": "KS5GZK0P6mwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clonagem do repositório Tensorflow Models"
      ],
      "metadata": {
        "id": "dFcFcaGf79Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "-16PIVbd7_g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do Tensorboard"
      ],
      "metadata": {
        "id": "8ZjVgmDO8Bgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "id": "4-ucM6-88B2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do ambiente"
      ],
      "metadata": {
        "id": "kZisBrI38KwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "id": "VKgAyat38LQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusão da instalação do Tensorboard"
      ],
      "metadata": {
        "id": "3VleKi8W8Sfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = \"/root/models/trained\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "#The link to tensorboard.\n",
        "#works after the training starts.\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "id": "qIseMoil8S2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Coleção de imagens, criação do das labels nos dados e criação do mapa das labels**"
      ],
      "metadata": {
        "id": "QvvGtB8f8jGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro passo efetuado nesta etapa foi a coleção de imagens para a criação de um dataset. Para realizar essa tarefa, utilizamos o código demonstrado na primeira parte deste Colab Notebook, em que fomos transferir as imagens do dataset nuImages para um Google Drive."
      ],
      "metadata": {
        "id": "W-Nq14fJ8jkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De seguida, utilizamos um programa denominado de labelImg, que pode ser instalado numa máquina Windows (que possua uma versão recente de Python e o Pip), com o comando demonstrado abaixo, e utilizamos esse programa para anotar as imagens com quais os objetos que queremos que este referencie, a localização dos mesmos e o seu respetivo nome."
      ],
      "metadata": {
        "id": "B4Z6F5wN8rq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install labelImg #o comando deve ser corrido sem o \"!\" na máquina local"
      ],
      "metadata": {
        "id": "zUHr5xiG8w7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O dataset que foi transferido na sua totalidade possui 465 imagens, logo, e com a finalidade de testar a rede neural e conseguir que a mesma esteja a funcionar, decidimos começar por selecionar apenas uma parte das imagens colecionadas, neste caso 49 imagens que compõem o dataset \"sample\" do nuImages."
      ],
      "metadata": {
        "id": "TFsD6aKF80X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois da anotação de cada imagem, é criado um ficheiro XML que fornece as informações acerca das anotações que foram efetuadas, sendo que iremos fornecer um exemplo de um desses ficheiros de seguida."
      ],
      "metadata": {
        "id": "z_-SUuFc82rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#este é o exemplo de um dos ficheiros XML gerados, que teve de ser apropriamente anotado pois não se trata de uma linguagem permitida pelo Colab\n",
        "#<annotation>\n",
        "#\t<folder>images</folder>\n",
        "#\t<filename>3.jpg</filename>\n",
        "#\t<path>C:\\Users\\rborreic\\Desktop\\Projects\\RedeNeural\\images\\3.jpg</path>\n",
        "#\t<source>\n",
        "#\t\t<database>Unknown</database>\n",
        "#\t</source>\n",
        "#\t<size>\n",
        "#\t\t<width>1600</width>\n",
        "#\t\t<height>900</height>\n",
        "#\t\t<depth>3</depth>\n",
        "#\t</size>\n",
        "#\t<segmented>0</segmented>\n",
        "#\t<object>\n",
        "#\t\t<name>car</name>\n",
        "#\t\t<pose>Unspecified</pose>\n",
        "#\t\t<truncated>0</truncated>\n",
        "#\t\t<difficult>0</difficult>\n",
        "#\t\t<bndbox>\n",
        "#\t\t\t<xmin>638</xmin>\n",
        "#\t\t\t<ymin>419</ymin>\n",
        "#\t\t\t<xmax>706</xmax>\n",
        "#\t\t\t<ymax>469</ymax>\n",
        "#\t\t</bndbox>\n",
        "#\t</object>\n",
        "#\t<object>\n",
        "#\t\t<name>van</name>\n",
        "#\t\t<pose>Unspecified</pose>\n",
        "#\t\t<truncated>0</truncated>\n",
        "#\t\t<difficult>0</difficult>\n",
        "#\t\t<bndbox>\n",
        "#\t\t\t<xmin>772</xmin>\n",
        "#\t\t\t<ymin>409</ymin>\n",
        "#\t\t\t<xmax>862</xmax>\n",
        "#\t\t\t<ymax>502</ymax>\n",
        "#\t\t</bndbox>\n",
        "#\t</object>\n",
        "#</annotation>"
      ],
      "metadata": {
        "id": "jgSRGZn78-Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dando por terminadas as anotações no nosso dataset de teste, iremos então proceder ao upload dos ficheiros para o Colab. Para simplificar este processo iremos clonar as imagens, que foram entretanto depositadas no repositório GitHub do projeto para a pasta do tensorflow models que foi clonada anteriormente."
      ],
      "metadata": {
        "id": "JrkYRIcw86kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /root/models/RedeNeural/ #Delete all files located in RedeNeural directory\n",
        "#!rm -r /root/models/RedeNeural #Delete RedeNeural folder"
      ],
      "metadata": {
        "id": "zZKjEIWb9nxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/models/\n",
        "!git clone https://github.com/ruiborreicho/RedeNeural"
      ],
      "metadata": {
        "id": "I-gy4Ujf9olO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Criação de um label map**"
      ],
      "metadata": {
        "id": "N-VUiwfc9khB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação de um label map, uma representação de todos os objetos que expectamos encontrar dentro das anotações criadas (ficheiros XML)"
      ],
      "metadata": {
        "id": "R2a1KrnO9tgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [{'name':'car', 'id':1}, {'name':'truck', 'id':2}, {'name':'motorbike', 'id':3}, {'name':'bus', 'id':4}, {'name':'van', 'id':5}, {'name':'bike', 'id':6}]"
      ],
      "metadata": {
        "id": "jxLIumGq9vyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/models/RedeNeural/annotations\n",
        "with open('labelMap.pbtxt', 'w') as f:\n",
        "  for label in labels:\n",
        "    f.write('item{\\n')\n",
        "    f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "    f.write('\\tid:{}\\n'.format(label['id']))\n",
        "    f.write('}\\n')"
      ],
      "metadata": {
        "id": "rkvYk-lF9wUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Criação dos TFRecords**"
      ],
      "metadata": {
        "id": "urmy1dJ391-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilização do ficheiro generate_tfrecord.py, fornecido pelo tutorial oficial do Object Detection API, que permite a conversão dos dados para o formato requirido pelo modelo."
      ],
      "metadata": {
        "id": "BUPX3Sa196kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python {'/root/models/RedeNeural/tfrecord/generate_tfrecord.py'} -x {'/root/models/RedeNeural/images/train'} -l {'/root/models/RedeNeural/annotations/labelMap.pbtxt'} -o {'/root/models/RedeNeural/annotations/train.record'}\n",
        "!python {'/root/models/RedeNeural/tfrecord/generate_tfrecord.py'} -x {'/root/models/RedeNeural/images/test'} -l {'/root/models/RedeNeural/annotations/labelMap.pbtxt'} -o {'/root/models/RedeNeural/annotations/test.record'}"
      ],
      "metadata": {
        "id": "U7loasRo92UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transferência e setup do SSD MobileNet v2**"
      ],
      "metadata": {
        "id": "GhIW9N0W-MhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para realizarmos o treino do nosso modelo iremos utilizar um modelo já existente para ajudar no processo, sendo o escolhido o SSD MobileNet v2. Nos próximos passos iremos fazer a transferência, movimentação do ficheiro transferido e a descompressão do mesmo."
      ],
      "metadata": {
        "id": "5WIcNm_E-NVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iremos agora criar uma diretoria com o nome de \"my_ssd_mobnet\" onde iremos copiar o ficheiro de pipeline.config do modelo já existente."
      ],
      "metadata": {
        "id": "64scdwv_-QMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /root/models/my_ssd_mobnet\n",
        "!cp {'/root/models/RedeNeural/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'} {'/root/models/my_ssd_mobnet/'}"
      ],
      "metadata": {
        "id": "PLheo5L6-ThF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Update no ficheiro de config para a transferência do conhecimento**"
      ],
      "metadata": {
        "id": "UBeTvT2H-VrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de darmos por inicio ao update do ficheiro, serão necessárias importar algumas dependências."
      ],
      "metadata": {
        "id": "om6PP5fS-Xrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "E5tCyYkZ-e1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do caminho até ao ficheiro de config"
      ],
      "metadata": {
        "id": "nxE_C9dA-jqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_PATH = '/root/models/my_ssd_mobnet/pipeline.config'"
      ],
      "metadata": {
        "id": "EpEiSXWn-mPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defenition of the training parameters on the pipeline.config file"
      ],
      "metadata": {
        "id": "crgm5rWW-oK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config) "
      ],
      "metadata": {
        "id": "JKabwH98-ooV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config.model.ssd.num_classes = 6\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = '/root/models/RedeNeural/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path = '/root/models/RedeNeural/annotations/labelMap.pbtxt'\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = ['/root/models/RedeNeural/annotations/train.record']\n",
        "pipeline_config.eval_input_reader[0].label_map_path = '/root/models/RedeNeural/annotations/labelMap.pbtxt'\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['/root/models/RedeNeural/annotations/test.record']"
      ],
      "metadata": {
        "id": "bHQN4-O9-tl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escrita dos parametros no ficheiro pipeline.config"
      ],
      "metadata": {
        "id": "_EcE6j_0-xXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)  "
      ],
      "metadata": {
        "id": "rIR4iROc-x5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Treino do modelo**"
      ],
      "metadata": {
        "id": "2b55ao4j_f-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comando que inicia o treino do modelo, sendo que é possível aumentar o número de train_steps para que o treino seja mais aprofundado."
      ],
      "metadata": {
        "id": "SmETZZLN_hYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /root/models/research/object_detection/model_main_tf2.py --model_dir=/root/models/my_ssd_mobnet --pipeline_config_path=/root/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000"
      ],
      "metadata": {
        "id": "glAto08z_hsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportação do modelo"
      ],
      "metadata": {
        "id": "TNpYVaQv_2d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /root/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir /root/models/my_ssd_mobnet/ \\\n",
        "    --output_directory /root/models/ \\\n",
        "    --pipeline_config_path /root/models/my_ssd_mobnet/pipeline.config"
      ],
      "metadata": {
        "id": "9Uc_0whE_3BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento do modelo"
      ],
      "metadata": {
        "id": "f3W63EzfACZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap('/root/models/RedeNeural/annotations/labelMap.pbtxt', use_display_name=True)\n",
        "model = tf.saved_model.load('/root/models/saved_model')"
      ],
      "metadata": {
        "id": "60dVR4CgACws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Teste do modelo**"
      ],
      "metadata": {
        "id": "MDwdbeqOArxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das bibliotecas necessárias"
      ],
      "metadata": {
        "id": "l8658FFABLmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import ops as utils_ops"
      ],
      "metadata": {
        "id": "hZnuOYFlBL89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função para carregar uma imagem para um NumPy Array"
      ],
      "metadata": {
        "id": "ftkNS545AyMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "metadata": {
        "id": "qcpkIE9ZAyzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função para correr a inferência numa imagem singular"
      ],
      "metadata": {
        "id": "L4_-1TfiAzFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ],
      "metadata": {
        "id": "NO29EUniAzjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correr a inferência"
      ],
      "metadata": {
        "id": "fQXVZ46ZA0Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = ['/root/models/RedeNeural/images/test/17.jpg', '/root/models/RedeNeural/images/test/20.jpg', '/root/models/RedeNeural/images/test/46.jpg', '/root/models/RedeNeural/images/test/5.jpg']\n",
        "\n",
        "for image_name in images:\n",
        "  \n",
        "  image_np = load_image_into_numpy_array(image_name)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "  vis_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np,\n",
        "                output_dict['detection_boxes'],\n",
        "                output_dict['detection_classes'],\n",
        "                output_dict['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.5,\n",
        "                agnostic_mode=False)\n",
        "  display(Image.fromarray(image_np))"
      ],
      "metadata": {
        "id": "XlP-itSWA0ZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}